                                                 Redis


Redis stands for REmote DIctionary Server.

Remote : Distributed
Dictionary : Hastable/Map/HashMap

Data structure which stores data and which is distributed.

Redis is written in c language. Redis is written on unix platforms- linux,osx.


Redis distribution

Mode of Distribution:

1.Open source - Redis.io
2.Commerical  - Redis cloud - redislabs

Redis Platform:
..............
Redis is officially available on unix,linux,bsd versions only.
redis is not available on windows.

Redis is available on windows 
-via docker.
-via third party - it is not stable.

Ridis use cases:
...............

1.caching.
2.Session management
3.Message broker
4.Gaming
5.as database.


Redis installation:
..................
->source code : build from source
->binary
//////////////////////////////////////////////////////////////////////////////////////////

How to install redis?

-open source - on linux

 - build from source.

-open source - on windows
  -docker - for development only.

Steps:
1.sudo apt-get update
2.wget https://download.redis.io/releases/redis-6.2.1.tar.gz
3.tar xzf redis-6.2.1.tar.gz
4.install compilers
5.build using make.

redis distribution dir structure:

1.redis-6.0.9/src
 -all source code - .c and .h files

2.redis-6.0.9/deps
 contains all compiler related things- cc, gcc.
 in order compile the files we need compilers
 memory allocators
3.redis-6.0.9/tests
   To test stability of redis components.

4.redis-6.0.9/utils
   contains ulities for administration,dev,testing redis.

Files:

bug reports:https://github.com/redis/redis/issues

redis configuration file:
redis.conf
  Redis server uses this file for starting and applying all redis admin features  
 

Lab 1: How to run redis server?

redis server can be started in two mode in general

1.log mode

$ src/redis-server

27874:C 15 Mar 2021 11:20:14.207 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
27874:C 15 Mar 2021 11:20:14.207 # Redis version=6.2.1, bits=64, commit=00000000, modified=0, pid=27874, just started
27874:C 15 Mar 2021 11:20:14.207 # Warning: no config file specified, using the default config. In order to specify a config file use src/redis-server /path/to/redis.conf
27874:M 15 Mar 2021 11:20:14.208 * Increased maximum number of open files to 10032 (it was originally set to 1024).
27874:M 15 Mar 2021 11:20:14.208 * monotonic clock: POSIX clock_gettime
                _._
           _.-``__ ''-._
      _.-``    `.  `_.  ''-._           Redis 6.2.1 (00000000/0) 64 bit
  .-`` .-```.  ```\/    _.,_ ''-._
 (    '      ,       .-`  | `,    )     Running in standalone mode
 |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379
 |    `-._   `._    /     _.-'    |     PID: 27874
  `-._    `-._  `-./  _.-'    _.-'
 |`-._`-._    `-.__.-'    _.-'_.-'|
 |    `-._`-._        _.-'_.-'    |           http://redis.io
  `-._    `-._`-.__.-'_.-'    _.-'
 |`-._`-._    `-.__.-'    _.-'_.-'|
 |    `-._`-._        _.-'_.-'    |
  `-._    `-._`-.__.-'_.-'    _.-'
      `-._    `-.__.-'    _.-'
          `-._        _.-'
              `-.__.-'

27874:M 15 Mar 2021 11:20:14.208 # Server initialized
27874:M 15 Mar 2021 11:20:14.208 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.
27874:M 15 Mar 2021 11:20:14.209 * Loading RDB produced by version 6.2.1
27874:M 15 Mar 2021 11:20:14.209 * RDB age 50 seconds
27874:M 15 Mar 2021 11:20:14.209 * RDB memory usage when created 0.83 Mb
27874:M 15 Mar 2021 11:20:14.209 * DB loaded from disk: 0.000 seconds
27874:M 15 Mar 2021 11:20:14.209 * Ready to accept connections


2.detached mode - back ground process.

Since redis is a c program, which has main method.

int main(char* args){
  chars *myargs=args;
}
args are used to pass command line args- options; value we pass to process during runtime.

syntax :

src/redis-server  --options

eg:
$src/redis-server --daemonize yes



Lab 2 : how to connect redis server?

 you need to communicate redis server, we need redis clients.

Redis can be connected with most of the programming languages
     -java, javascript,python,c#,Ruby,C,C++..........

Every programming lang has dirivers to connect redis server.

Redis offers built in cli tool - redis-cli
 command line tool to talk to redis server.
this tool mostly used by administors

Lab 3: How to connect redis via redis cli?

Hand shaking processing:

$src/redis-cli
127.0.0.1:6379> PING
PONG
127.0.0.1:6379> PING "Hello Redis!"
"Hello Redis!"
127.0.0.1:6379>

Lab 4 : How to stop running redis server?

>127.0.0.1:6379> shutdown
not connected>

after shutting down, if you try to connect server you will get the following error.

Could not connect to Redis at 127.0.0.1:6379: Connection refused.

Lab 5: How to change default port?

--port parameter

$src/redis-server --port 6380

How to connect via cli if port is different

 src/redis-cli
Could not connect to Redis at 127.0.0.1:6379: Connection refused

by default redis-cli has been configured to connect with 6379 port only. if port change
we need to tell explicit port.

Like redis server redis-cli takes parameter, parameter should be passed with "-" 
 -p

$src/redis-cli -p 6380

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

Lab 6: How to start multiple redis instances?

redis can be started n-no of instances.

Redis server can be classified into 2 category based on server startup?

1.standalone mode

2.Replica mode
  2.1.cluster mode

Multiple redis instances in standalone mode?
 just run servers in different ports.
 
src/redis-server --daemonize yes
src/redis-server --daemonize yes --port 6380
src/redis-server --daemonize yes --port 6381

src/redis-cli 

src/redis-cli -p 6380
src/redis-cli -p 6381
//////////////////////&&&&&&&&&&&&&&&&&/////////////////////////////////////////////////////

Task : How to inspect redis.conf file.

1.Redis is able to start without a configuration file using a "built-in default configuration".
2.However this setup is only recommended for testing and development purposes.
3.redis conf file has values defined by "directives".
  directive is just variable having value.
 
   keyword arg1 arg2 argN
   (directive)

   daemonize no

3.# - symbol is used to disable configuration or to represent documentation

   # Genernal 

///////////////////////////////////////////////////////////////////////////////////////////

Redis General Concepts:


1.Redis is key-value pair data store.

 Data storage in redis is based keys.
 A key can be maped with single or compsit values.

2.Redis provides data structures such as strings, hashes, lists, sets, sorted sets with range queries, bitmaps, hyperloglogs, geospatial indexes, and streams.

3.commands ;
  like sql commands(select,insert,update,grant,commit) , redis offers commands.
  commands are apis supplied to redis-server will run command and will give response.

 generally commands are classified into 2.

  - request related (write) - Set
  - response related (read) - get


Lab 7: How to save simple data into redis server?
Command:

SET 
GET

SET key value [EX seconds|PX milliseconds|KEEPTTL] [NX|XX] [GET]

127.0.0.1:6379> SET message "Hello Redis!!"
OK

Here We send key via set command to server, server will execute that command, stores data with
key-value, once success it returns RESPONSE - OK.

GET key

127.0.0.1:6379> GET message
"Hello Redis!!"
/////////////////////////////////////////////////////////////////////////////////////////////
Commands: Keys:
..............

How to read all keys or some of the keys?

 KEYS
 SCAN

Returns all keys matching pattern.

127.0.0.1:6379> KEYS *
1) "message"

127.0.0.1:6379> KEYS m?ssage
1) "message"

Redis uses glob-style pattern similar to regex pattern.
https://en.wikipedia.org/wiki/Glob_(programming) - *,?,?? []


Keys
-Blocks until complete
   lets say database contains million keys, it blocks database long time
 Recommendation : dont use in production, use it in dev and testing env only.

Redis Process Architecture:
...........................

1.Redis is single threaded.
  
Non blocking and async arch.
   Redis since single threaded all heavy or long running process are handed over to kernal 
space like epoll or Kqueue.

Redis server is async non blocking server.
 Redis can schedule long running tasks in the background, without affecting the running
 redis server



Scan :
  iterates over cursor
  it also blocks but only iterates over handful  of keys at  the time.
  Returns slot references
  May return 0 or more keys per call.
  Safe for production.


127.0.0.1:6379> scan 0 MATCH *
1) "15"
2)  1) "a"
    2) "c1"
    3) "c"
    4) "d"
    5) "d1"
    6) "b"
    7) "message"
    8) "e"
    9) "a1"
   10) "e1"
127.0.0.1:6379> scan 15 MATCH *
1) "15"
2)  1) "a"
    2) "c1"
    3) "c"
    4) "d"
    5) "d1"
    6) "b"
    7) "message"
    8) "e"
    9) "a1"
   10) "e1"
127.0.0.1:6379> scan 0 MATCH * COUNT 4
1) "14"
2) 1) "a"
   2) "c1"
   3) "c"
   4) "d"
127.0.0.1:6379> scan 14 MATCH * COUNT 4
1) "9"
2) 1) "d1"
   2) "b"
   3) "message"
   4) "e"
127.0.0.1:6379> scan 9 MATCH * COUNT 4
1) "0"
2) 1) "a1"
   2) "e1"
   3) "b1"
127.0.0.1:6379> scan 0 MATCH * COUNT 4
1) "14"
2) 1) "a"
   2) "c1"
   3) "c"
   4) "d"
127.0.0.1:6379>

//////////////////////////////////////////////////////////////////////////////////////////////
Redis Key Modeling Patterns: Redis community Recommendation:
............................................................

KEY NAME:

Plain keynames
   A    10
   X    20
   name "subramanian"

Redis coding standard:
  objectname:identifier:subidentifier

i want to store order status

  order:1  available
  order:2  outofstock
  order:3  pending
  user:1:status online

127.0.0.1:6379> SET order:1 "available"
OK
127.0.0.1:6379> SET order:1 "available"
OK
127.0.0.1:6379> get order:2 "outofstock"
OK
127.0.0.1:6379> set user:1:status online
OK
127.0.0.1:6379> set user:2:status online
OK
127.0.0.1:6379> set user:3:status offline


////////////////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////////////////////

KEYS REMOVAL: DEL and Unlink
/////////////////////////////


KEYS REMOVAL: DEL and Unlink
/////////////////////////////


DEL key [key ...]

Removes the specified keys. A key is ignored if it does not exist.

Return value
Integer reply: The number of keys that were removed.

-The DEL Command will remove the key and memory associated with the key.
-This is performed as a blocking opertion.

UnLink:
......
-With UNLINK, key is unlinked , hence the name of the  command and will no longer exists.
-The memory associated with the key value is reclaimed by an asynchronous process,so the UNLINK is a  non-blocking command.


127.0.0.1:6379> DEL a
(integer) 1
127.0.0.1:6379> DEL a a1
(integer) 1
127.0.0.1:6379> DEL b b1
(integer) 2
127.0.0.1:6379> UNLINK  c c1
(integer) 2
127.0.0.1:6379> get c
(nil)
127.0.0.1:6379> get a
(nil)
127.0.0.1:6379>

Note:
 if key does not exit , it returns "nil"



///////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////

However, there are times when you only want to set the value if the key already exists.

EXISTS key [key ...]

EXISTS customer:1000
127.0.0.1:6379> EXISTS customer:2000
(integer) 1
127.0.0.1:6379> EXISTS customer:9000
(integer) 0
127.0.0.1:6379>

it returns 1 for key present , 0 means no key present



Use case :

Why should i use exits command to verify the existing of key.

Operations:
 - new Key - insert
 - update key  -  update.

-SET Command
127.0.0.1:6379> SET customer:9000 jane
OK
127.0.0.1:6379> GET customer:9000
"jane"

what if i want to update customer name of customer:9000
SET Command

127.0.0.1:6379> SET customer:9000 "jane james"
OK
127.0.0.1:6379> GET customer:9000
"jane james"
127.0.0.1:6379>


127.0.0.1:6379> EXISTS customer:9000
(integer) 0
127.0.0.1:6379> SET customer:9000 jane
OK

You could first check with the exist command to see if the key is present before using SET.

But having two operations-- the exists followed by a set--means two round trips Redis and possible inconsistencies between the operations.


127.0.0.1:6379> EXISTS customer:9000
(integer) 0
127.0.0.1:6379> SET customer:9000 jane
OK

You could first check with the exist command to see if the key is present before using SET.

But having two operations-- the exists followed by a set--means two round trips Redis and possible inconsistencies between the operations.

NX -  for create
XX -  for update.

127.0.0.1:6379> SET customer:333 john NX
OK
127.0.0.1:6379> SET customer:333 john NX
(nil)
127.0.0.1:6379> SET customer:444 Karthik XX
(nil)
127.0.0.1:6379> SET customer:444 Karthik NX
OK
127.0.0.1:6379> SET customer:444 Karthik.K XX
OK
127.0.0.1:6379> GET customer:444
"Karthik.K"
127.0.0.1:6379>
/////////////////////////////////////////////////////////////////////////////////////////

/////////////////////////////////////////////////////////////////////////////////////////////

Key removals:

1.you can remove key through commands - del,unlink. 
  This is not good idea , incase large amount of keys... -

2. auto delete ;
   it is good idea , when key is not usefull after some process/time.

Timers : Automatic Key Eviction:
.................................
timeout in sec- ex
timeout in msc -px
TTL key - to verify , how much time is there 
expire key sec - used to set timeout after key creation

Timers : Automatic Key Eviction:
.................................
timeout in sec- ex
timeout in msc -px
TTL key - to verify , how much time is there 
	
27.0.0.1:6379> SET seat-hold Row:A:Seat:4 EX 5000
OK
127.0.0.1:6379> get seat-hold
"Row:A:Seat:4"
127.0.0.1:6379> get seat-hold
"Row:A:Seat:4"
127.0.0.1:6379> get seat-hold
"Row:A:Seat:4"
127.0.0.1:6379> TTL seat-hold
(integer) 4957
127.0.0.1:6379> TTL seat-hold
(integer) 4952
127.0.0.1:6379> SET user:password something PX 10000
OK
127.0.0.1:6379> TTL user:password
(integer) -2
127.0.0.1:6379> get user:password
(nil)
127.0.0.1:6379> exists user:password
(integer) 0
127.0.0.1:6379> SET user:password something PX 10000
OK
127.0.0.1:6379> exists user:password
(integer) 1
127.0.0.1:6379> get user:password
"something"
127.0.0.1:6379> get user:password
(nil)
127.0.0.1:6379>


127.0.0.1:6379> expire customer:444 10
(integer) 1
127.0.0.1:6379> get customer:444
"Karthik.K"
127.0.0.1:6379> get customer:444
"Karthik.K"
127.0.0.1:6379> get customer:444
(nil)

//////////////////////////////////////////////////////////////////////////////////////////////

 //////////////////////////////////////////////////////////////////////////////////////////////

                                             Data types
1.String:
 -store alphabets
 -store numbers
 -store binary.
    -image,spreadsheets,html fragments

no int,float datatype.

There is a limit of 512 megabytes for any string value

JPEGs, Excel spreadsheets, HTML fragments, as well as
plain old regular text and numbers are permissible.

Internally, Redis stores encoding of the value, stores a knowledge of whether it is a text, number, or binary.
 1 - integer
 "a" - string
 binary - bytes-raw

How to know the type of key?

TYPE key


127.0.0.1:6379> SET  a 10
OK
127.0.0.1:6379> SET name "Subramanian"
OK
127.0.0.1:6379> SET b "10"
OK
127.0.0.1:6379> TYPE a
string
127.0.0.1:6379> TYPE name
string
127.0.0.1:6379> TYPE b
string
127.0.0.1:6379> SET c 10.5
OK
127.0.0.1:6379> TYPE c
string

Since string is Super Type, 10 also stored as string but it is numeric value.

Can i do some computation on numerical value.
Yes!

in order to know the internal type of string

OBJECT subcommand key

The OBJECT command allows to inspect the internals of Redis Objects associated with keys

OBJECT ENCODING <key> returns the kind of internal representation used in order to store the value associated with a key.


127.0.0.1:6379> SET  a 10
OK
127.0.0.1:6379> SET name "Subramanian"
OK
127.0.0.1:6379> SET b "10"
OK
127.0.0.1:6379> TYPE a
string
127.0.0.1:6379> TYPE name
string
127.0.0.1:6379> TYPE b
string
127.0.0.1:6379> SET c 10.5
OK
127.0.0.1:6379> TYPE c
string
127.0.0.1:6379> INCR a
(integer) 11
127.0.0.1:6379> INCR b
(integer) 11
127.0.0.1:6379> OBJECT ENCODING a
"int"
127.0.0.1:6379> OBJECT ENCODING b
"int"
127.0.0.1:6379> OBJECT ENCODING name
"embstr"
127.0.0.1:6379> OBJECT ENCODING c
"embstr"
127.0.0.1:6379> INCR name
(error) ERR value is not an integer or out of range
127.0.0.1:6379> INCR c
(error) ERR value is not an integer or out of range
127.0.0.1:6379> INCRBYFLOAT c
(error) ERR wrong number of arguments for 'incrbyfloat' command
127.0.0.1:6379> INCRBYFLOAT c 1
"11.5"
127.0.0.1:6379> INCRBYFLOAT c 1
"12.5"
127.0.0.1:6379> INCRBY a 10
(integer) 21
127.0.0.1:6379> INCRBY a 10
(integer) 31
127.0.0.1:6379> INCRBY a 10
(integer) 41
127.0.0.1:6379> INCRBY a -10
(integer) 31
127.0.0.1:6379> INCRBY a 10
(integer) 41
127.0.0.1:6379> INCRBY a -10
(integer) 31
127.0.0.1:6379> DECR a
(integer) 30
127.0.0.1:6379> DECRby a 5
(integer) 25
127.0.0.1:6379> DECRby a 5
(integer) 20
127.0.0.1:6379>
////////////////////////////////////////////////////////////////////////////////////////////
String operations:

-string length
-stringrange
-append

127.0.0.1:6379> STRLEN name
(integer) 11
127.0.0.1:6379> set name "Subramanian"
OK
127.0.0.1:6379> GETRANGE name 0 4
"Subra"
127.0.0.1:6379>

127.0.0.1:6379> APPEND name "Murugan"
(integer) 18
127.0.0.1:6379> get name
"SubramanianMurugan"
127.0.0.1:6379>
////////////////////////////////////////////////////////////////////////////////////////////
Bit Maps:
........

Collection of bits which forms a structure called bit map.

BitMaps are  a data type used within Redis and represents a long list of bits that contain 0 by default and we can use SETBIT Command to flip to 1 or 0


Key                    Value                               type
	
a_bitmap     0 0 0  0 0 0 0 0 0 0 0 0 0 0                  binary string


bitmap can store up to 2pow 32 bits,about 4 billion items

Use case: login use case

SETBIT logins:2017:04 6 1

here login:2017:04 is key
6 is offset , typically userid as offset
1 is active bit

SETBIT logins:2017:04 6 1

27.0.0.1:6379> SET login:today 7 1
(error) ERR syntax error
127.0.0.1:6379> SETBIT login:today 7 1
(integer) 0
127.0.0.1:6379> SETBIT login:today 7 0
(integer) 1
127.0.0.1:6379> GET login:today
"\x00"
127.0.0.1:6379> Type login:today
string
127.0.0.1:6379> object encoding login:today
"raw"
127.0.0.1:6379>

types:
 int -numbers
 embstr -embededstring
 raw - binary- bits
/////////////////////////////////////////////**************//////////////////////////////////
/////////////////////////////////////////////**************//////////////////////////////////

Hash:
.....

String stores single/scalar value only

 SET a 10

Hash Stores key-value pair values into one single key

    player:1
        name:xxx
        score:12
        status:available

H-SET =>HashSet

HSET key field value [field value ...]

127.0.0.1:6379> HSET player:1 name Subramanian score 80 status alive
(integer) 3
127.0.0.1:6379> HSET houseId:5150 numBedrooms 3 sqfeet 2700 hvac "forced air"
(integer) 3
1

internal represention would be like below
  
player:1 
       {
         name:'subramanina',
         score:80,
         status:'alive'
       }


houseID: 5150
	numBedrooms: 3
	squareFeet: 2700
	hvac: forced air


Commands:

HSET - to add field and values
HGETALL - to read all hash values
HGET  - TO get a particular key value
HSET - to update existing field or add new field value
HDEL - to delete a field value from existing hash
HINCRBY - to increment a field value

Reading Keys and key
......................
127.0.0.1:6379> HGETALL player:1
1) "name"
2) "Subramanian"
3) "score"
4) "80"
5) "status"
6) "alive"
127.0.0.1:6379> HGET player:1 name
"Subramanian"
127.0.0.1:6379> HGET player:1 status
"alive"
127.0.0.1:6379>


////////////////////////////////////////////////////////////////////////////////////////////
How to maniupulate a field in hashset?

HINCRBY key field increment
HINCRBYFLOAT key field increment

127.0.0.1:6379> HINCRBY player:1  score 5
(integer) 85
127.0.0.1:6379> HINCRBY player:1  score 5
........................................................

........................................................

How to update existing fields in hash set?

You can update single field or multiple fields?

127.0.0.1:6379> HSET player:1 name "Ram Kumar"
(integer) 0
127.0.0.1:6379> HGET player:1 name
"Ram Kumar"
127.0.0.1:6379> HSET player:1 name "Ram Kumar" score 10
(integer) 0
127.0.0.1:6379> HGETALL player:1
1) "name"
2) "Ram Kumar"
3) "score"
4) "10"
5) "status"
6) "alive"
127.0.0.1:6379>
.......................................................................................
.......................................................................................
How to add new field on existing hash?

127.0.0.1:6379> HSET player:1  level 5
(integer) 1
127.0.0.1:6379> HGETALL player:1
1) "name"
2) "Ram Kumar"
3) "score"
4) "10"
5) "status"
6) "alive"
7) "level"
8) "5"
127.0.0.1:6379>
////////////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////////

How to delete field/s from hash?

HDEL key field [field ...]

27.0.0.1:6379> HGETALL player:1
1) "name"
2) "Ram Kumar"
3) "score"
4) "10"
5) "status"
6) "alive"
7) "level"
8) "5"
127.0.0.1:6379> HDEL player:1 status
(integer) 1
127.0.0.1:6379> HGETALL player:1
1) "name"
2) "Ram Kumar"
3) "score"
4) "10"
5) "level"
6) "5"
127.0.0.1:6379>

///////////////////////////////////////////////////////////////////////////////////////////

///////////////////////////////////////////////////////////////////////////////////////////

How to verify a particular field present or not on existing hash?

HEXISTS key field

127.0.0.1:6379> HEXISTS player:1 status
(integer) 0
127.0.0.1:6379> HEXISTS player:1 level
(integer) 1
127.0.0.1:6379>
...........................................................................................

...........................................................................................
How to extract only keys and values from Hash?

Keys Only:

127.0.0.1:6379> HKEYS player:1
1) "name"
2) "score"
3) "level"

Values Only:
127.0.0.1:6379> HVALS player:1
1) "Ram Kumar"
2) "10"
3) "5
//////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////
                                     List
                                   .........

1.List is ordered collection of strings.
2.List maintains order based index, which starts 0th index.
3.Lists are dynamic array,you can add,delete items dynamically, as you add or delete,
  the size of list automatically expanded or shrinked.
4.Lists are implemented as "Doubly Linked List" : Linked List
5.You can add element at any position :  head / tail - left /right.
6.You can create other usefull data structures like "Queues/ Stacks,PQueues"
7.Duplicates are allowed.

//////////////////////////////////////////////////////////////////////////////////////////////
                                     List
                                   .........

1.List is ordered collection of strings.
2.List maintains order based index, which starts 0th index.
3.Lists are dynamic array,you can add,delete items dynamically, as you add or delete,
  the size of list automatically expanded or shrinked.
4.Lists are implemented as "Doubly Linked List" : Linked List
5.You can add element at any position :  head / tail - left /right.
6.You can create other usefull data structures like "Queues/ Stacks,PQueues"
7.Duplicates are allowed.

List Operations:

1.Add Elements at Head

LPUSH key element [element ...]

127.0.0.1:6379> LPUSH  names a b c d e
(integer) 5
127.0.0.1:6379>

............................................................

2.Get No of elemenents In the List

LLEN key

127.0.0.1:6379> LLEN names
(integer) 5
...................................................................
3.How read elements from left most?

127.0.0.1:6379> LPUSH  names a b c d e
(integer) 5

LPush adds element left side

Internal storage would be for LPUSH 
 e,d,c,a,b

127.0.0.1:6379> LRANGE names 0 5
1) "e"
2) "d"
3) "c"
4) "b"
5) "a"
127.0.0.1:6379> LRANGE names 2 5
1) "c"
2) "b"
3) "a"
127.0.0.1:6379> LRANGE names 3 5
1) "b"
2) "a"
...........................................................................................
3.1. How to read single element based on index?

LINDEX key index

 - 0 means first index element
 - -1 last tail element
 - outofindex - nil

127.0.0.1:6379> LRANGE names 0 7
1) "c"
2) "redis-cli"
3) "b"
4) "a"

Get the first element:

127.0.0.1:6379> LINDEX names 0
"c"

127.0.0.1:6379> LINDEX names 1
"redis-cli"
127.0.0.1:6379> LINDEX names -1
"a"
127.0.0.1:6379> LINDEX names -2
"b"
127.0.0.1:6379> LINDEX names 90
(nil)
127.0.0.1:6379>

/////////////////////////////////////////////////////////////////////////////////////////////

How to update/replace old node value into new node value?

Before update:
127.0.0.1:6379> LRANGE names 0 5
1) "e"
2) "d"
3) "c"
4) "b"
5) "a"

After update:
127.0.0.1:6379> LSET  names 0 "foo"
OK
127.0.0.1:6379> LRANGE names 0 5
1) "foo"
2) "d"
3) "c"
4) "b"
5) "a"
////////////////////////////////////////////////////////////////////////////////////////////

How to add element in the middle of the List?

LINSERT key BEFORE|AFTER pivot element


127.0.0.1:6379> LRANGE names 0 5
1) "foo"
2) "d"
3) "c"
4) "b"
5) "a"
127.0.0.1:6379> LINSERT names BEFORE "c" "redis"
(integer) 6
127.0.0.1:6379> LRANGE names 0 6
1) "foo"
2) "d"
3) "redis"
4) "c"
5) "b"
6) "a"
127.0.0.1:6379> LINSERT names AFTER "c" "redis-cli"
(integer) 7
127.0.0.1:6379> LRANGE names 0 7
1) "foo"
2) "d"
3) "redis"
4) "c"
5) "redis-cli"
6) "b"
7) "a"
///////////////////////////////////////////////////////////////////////////////////////////
How to remove element from the Left side?

LPOP key

Before Remove:
..............

127.0.0.1:6379> LRANGE names 0 7
1) "foo"
2) "d"
3) "redis"
4) "c"
5) "redis-cli"
6) "b"
7) "a"
127.0.0.1:6379> LPOP names
"foo"
127.0.0.1:6379> LPOP names
"d"
127.0.0.1:6379> LPOP names
"redis"

After Remove:
.............

127.0.0.1:6379> LRANGE names 0 7
1) "c"
2) "redis-cli"
3) "b"
4) "a"
127.0.0.1:6379>
////////////////////////////////////////////////////////////////////////////////////////////

RPUSH : Pushing elements towards right
......................................

RPUSH key element [element ...]

Add elements:

127.0.0.1:6379> RPUSH  counters 1 2 3 4 5 6 7 8 9 10
(integer) 10

127.0.0.1:6379> LRANGE counters 0 9
 1) "1"
 2) "2"
 3) "3"
 4) "4"
 5) "5"
 6) "6"
 7) "7"
 8) "8"
 9) "9"
10) "10"

127.0.0.1:6379> LRANGE counters 0 9
 1) "1"
 2) "2"
 3) "3"
 4) "4"
 5) "5"
 6) "6"
 7) "7"
 8) "8"
 9) "9"
10) "10"
127.0.0.1:6379> RPOP counters
"10"
127.0.0.1:6379> LPOP counters
"1"
127.0.0.1:6379>
/////////////////////////////////////////////////////////////////////////////////////////

Think how to implement stacks and queues using list?
.....................................................

STACK - LPUSH ,LPOP
Queue - RPUSH, LPOP
.........................................................................................

........................................................................................

                                      SET
............................................................................................ 

Sets:
 -Unordered collection without duplicate values.
 -Provides mathmetical set operations - union,intersection,difference.

How to create set / how to add elements set?

SADD key member [member ...]

127.0.0.1:6379> SADD hitcounters 1 1 2 3 3 4 5 6 7 8 8
(integer) 8

How to get all keys and values?

SSCAN key cursor [MATCH pattern] [COUNT count]

127.0.0.1:6379> SSCAN hitcounters 0 MATCH *
1) "0"
2) 1) "1"
   2) "2"
   3) "3"
   4) "4"
   5) "5"
   6) "6"
   7) "7"
   8) "8"
127.0.0.1:6379>

////////////////////////////////////////////////////////////////////////////////////////

Cardinality: SCARD

SCARD key

-Returns the set cardinality (number of elements) of the set stored at key.

127.0.0.1:6379> SCARD hitcounters
(integer) 8

////////////////////////////////////////////////////////////////////////////////////////////

Differences:SDIFF

SDIFF key [key ...]

-Returns the members of the set resulting from the difference between the first set and all the successive sets.

127.0.0.1:6379> SADD key1 a b c d
(integer) 4
127.0.0.1:6379> SADD key2 c
(integer) 1
127.0.0.1:6379> SADD key3 a c e
(integer) 3
127.0.0.1:6379> SDIFF key1 key2 key3
1) "b"
2) "d"
////////////////////////////////////////////////////////////////////////////////////////////

Union : eleminate common elements

127.0.0.1:6379> sadd key1  a b c d e
(integer) 5
127.0.0.1:6379> sadd key2 c
(integer) 1
127.0.0.1:6379> sadd key3 f g c
(integer) 3
127.0.0.1:6379> sunion key1 key2 key3
1) "f"
2) "c"
3) "b"
4) "a"
5) "d"
6) "e"
7) "g"
127.0.0.1:6379>
///////////////////////////////////////////////////////////////////////////////////////////////
Intersection: Common element

SINTER key [key ...]

Returns the members of the set resulting from the intersection of all the given sets.

127.0.0.1:6379> SADD key1 a b c d
(integer) 4
127.0.0.1:6379> SADD key2 c
(integer) 1
127.0.0.1:6379> SADD key3 a c e

127.0.0.1:6379> SINTER key1 key2 key3
1) "c"

//////////////////////////////////////////////////////////////////////////////////////////

How to get members of a given set?

SMEMBERS key


127.0.0.1:6379> SMEMBERS key1
1) "c"
2) "d"
3) "b"
4) "a"
127.0.0.1:6379> SMEMBERS key2
1) "c"
127.0.0.1:6379> SMEMBERS key3
1) "c"
2) "e"
3) "a"
127.0.0.1:6379>
///////////////////////////////////////////////////////////////////////////////////////////

To test whether an element is member of a given set?

SISMEMBER key member
 
1-means memeber
0-means not a member

127.0.0.1:6379> SISMEMBER key1 a
(integer) 1
127.0.0.1:6379> SISMEMBER key1 ab
(integer) 0
127.0.0.1:6379>

////////////////////////////////////////////////////////////////////////////////////////////

How to remove element from Set?

Remove from first index

SPOP key [count]

127.0.0.1:6379> SMEMBERS key1
1) "c"
2) "d"
3) "b"
4) "a"
127.0.0.1:6379> SPOP key1
"a"
127.0.0.1:6379> SMEMBERS key1
1) "c"
2) "d"
3) "b"
127.0.0.1:6379> SPOP key1  2
1) "c"
2) "d"
127.0.0.1:6379> SMEMBERS key1
1) "b"
127.0.0.1:6379>

Remove based on element

SREM key member [member ...]

127.0.0.1:6379> SMEMBERS key1
1) "c"
2) "d"
3) "b"
4) "a"
5) "e"
127.0.0.1:6379> SREM key1 c
(integer) 1
127.0.0.1:6379> SMEMBERS key1
1) "d"
2) "b"
3) "a"
4) "e"
////////////////////////////////////////////////////////////////////////////////////////
How to select random values from the set?

SRANDMEMBER key [count]

127.0.0.1:6379> SRANDMEMBER key1
"d"
127.0.0.1:6379> SRANDMEMBER key1
"d"
127.0.0.1:6379> SRANDMEMBER key1
"b"
127.0.0.1:6379> SRANDMEMBER key1 2
1) "e"
2) "a"
127.0.0.1:6379> SRANDMEMBER key1 2
1) "d"
2) "b"
127.0.0.1:6379> SRANDMEMBER key1 2
1) "d"
2) "b"

//////////////////////////////////////////////////////////////////////////////////////////////
                                   
                                      SORTED SET
///////////////////////////////////////////////////////////////////////////////////////////////

 -Sorted set is similar to set with sorting feature. asc or dec order - based on numbers/charcaters

127.0.0.1:6379> ZADD myset 1 a
(integer) 1
127.0.0.1:6379> ZADD myset 1 a
(integer) 0
127.0.0.1:63
79> ZADD myset 1 b
(integer) 1
127.0.0.1:6379> ZADD myset 2 c 3 d
(integer) 2
127.0.0.1:6379> ZRANGE myset 0 -1 WITHSCORES
1) "a"
2) "1"
3) "b"
4) "1"
5) "c"
6) "2"
7) "d"
8) "3"
127.0.0.1:6379> ZRANGE myset 0 -1
1) "a"
2) "b"
3) "c"
4) "d"
127.0.0.1:6379> ZADD myset 0 e
(integer) 1
127.0.0.1:6379> ZRANGE myset 0 -1
1) "e"
2) "a"
3) "b"
4) "c"
5) "d"
127.0.0.1:6379> ZADD myset 10 foo
(integer) 1
127.0.0.1:6379> ZADD myset 5 bar
(integer) 1
127.0.0.1:6379> ZRANGE myset 0 -1
1) "e"
2) "a"
3) "b"
4) "c"
5) "d"
6) "bar"
7) "foo"
127.0.0.1:6379> ZADD myset 9 foobar
(integer) 1
127.0.0.1:6379> ZRANGE myset 0 -1
1) "e"
2) "a"
3) "b"
4) "c"
5) "d"
6) "bar"
7) "foobar"
8) "foo"
127.0.0.1:6379>

Note: 
 sorting happens based "score" values, incase scores are same, then redis sorts according to
 ordered lexicographically of values.

Note: Most of the Sort apis available inside Sorted Set + Some advanced apis also , which is based on scores and ranks.
/////////////////////////////////////////////////////////////////////////////////////////////
hyperloglogs, geospatial indexes, and streams -Advanced types
.............................................................................................

                                      Administration
.............................................................................................

RDBMS stores data inside schema.
Does redis stores data inside schema?
 yes!.....

Storage:

 Redis is 200% in memory data store -  all data is stored inside RAM.
 Redis stores data in logical isloation that is called db.
 Redis has default 16 databases(storage),named as 0,1- default is 0.

Lab 6 :Data base information:
selectdb 0 
 switching database to databse
swapdb 0 1
  move keys from 0 to 1 
flushdb 
  removes all keys in a selected db
flushall 
  removes all keys in all database
removes particular key
del 
unlink
//////////////////////////////////////////////////////////////////////////////////////////

Lab 7: How to start redis server with configuration?

Starting redis server with configuration?

./redis-server /path/to/redis.conf


src/redis-server redis.conf
14271:C 17 Mar 2021 09:35:36.898 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
14271:C 17 Mar 2021 09:35:36.898 # Redis version=6.2.1, bits=64, commit=00000000, modified=0, pid=14271, just started
14271:C 17 Mar 2021 09:35:36.898 # Configuration loaded
14271:M 17 Mar 2021 09:35:36.899 * Increased maximum number of open files to 10032 (it was originally set to 1024).
14271:M 17 Mar 2021 09:35:36.899 * monotonic clock: POSIX clock_gettime
                _._
           _.-``__ ''-._
      _.-``    `.  `_.  ''-._           Redis 6.2.1 (00000000/0) 64 bit
  .-`` .-```.  ```\/    _.,_ ''-._
 (    '      ,       .-`  | `,    )     Running in standalone mode
 |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6381
 |    `-._   `._    /     _.-'    |     PID: 14271
  `-._    `-._  `-./  _.-'    _.-'
 |`-._`-._    `-.__.-'    _.-'_.-'|
 |    `-._`-._        _.-'_.-'    |           http://redis.io
  `-._    `-._`-.__.-'_.-'    _.-'
 |`-._`-._    `-.__.-'    _.-'_.-'|
 |    `-._`-._        _.-'_.-'    |
  `-._    `-._`-.__.-'_.-'    _.-'
      `-._    `-.__.-'    _.-'
          `-._        _.-'
              `-.__.-'

14271:M 17 Mar 2021 09:35:36.900 # Server initialized
14271:M 17 Mar 2021 09:35:36.900 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.
14271:M 17 Mar 2021 09:35:36.901 * Loading RDB produced by version 6.2.1
14271:M 17 Mar 2021 09:35:36.901 * RDB age 310 seconds
14271:M 17 Mar 2021 09:35:36.901 * RDB memory usage when created 0.83 Mb
14271:M 17 Mar 2021 09:35:36.901 * DB loaded from disk: 0.000 seconds
14271:M 17 Mar 2021 09:35:36.901 * Ready to accept connections

/////////////////////////////////////////////////////////////////////////////////////////////

Lab 8 : How to inspect the redis server information?


Category of server information:
...............................

server: General information about the Redis server
clients: Client connections section
memory: Memory consumption related information
persistence: RDB and AOF related information
stats: General statistics
replication: Master/replica replication information
cpu: CPU consumption statistics
commandstats: Redis command statistics
cluster: Redis Cluster section
modules: Modules section
keyspace: Database related statistics
modules: Module related sections
errorstats: Redis error statistics


127.0.0.1:6379> info

# Server
redis_version:6.0.4
redis_git_sha1:00000000
redis_git_dirty:0
redis_build_id:d5d470262d47f1a0
redis_mode:standalone
os:Linux 5.4.39-linuxkit x86_64
arch_bits:64
multiplexing_api:epoll
atomicvar_api:atomic-builtin
gcc_version:8.3.0
process_id:1
run_id:40543dac7951c11291c95a053a7246e647b36305
tcp_port:6379
uptime_in_seconds:47891
uptime_in_days:0
hz:10
configured_hz:10
lru_clock:13047257
executable:/data/redis-server
config_file:

# Clients
connected_clients:2
client_recent_max_input_buffer:2
client_recent_max_output_buffer:0
blocked_clients:0
tracking_clients:0
clients_in_timeout_table:0

# Memory
used_memory:893520
used_memory_human:872.58K
used_memory_rss:7598080
used_memory_rss_human:7.25M
used_memory_peak:893520
used_memory_peak_human:872.58K
used_memory_peak_perc:100.17%
used_memory_overhead:837156
used_memory_startup:802848
used_memory_dataset:56364
used_memory_dataset_perc:62.16%
allocator_allocated:936504
allocator_active:1224704
allocator_resident:3592192
total_system_memory:2084323328
total_system_memory_human:1.94G
used_memory_lua:37888
used_memory_lua_human:37.00K
used_memory_scripts:0
used_memory_scripts_human:0B
number_of_cached_scripts:0
maxmemory:0
maxmemory_human:0B
maxmemory_policy:noeviction
allocator_frag_ratio:1.31
allocator_frag_bytes:288200
allocator_rss_ratio:2.93
allocator_rss_bytes:2367488
rss_overhead_ratio:2.12
rss_overhead_bytes:4005888
mem_fragmentation_ratio:8.93
mem_fragmentation_bytes:6747072
mem_not_counted_for_evict:0
mem_replication_backlog:0
mem_clients_slaves:0
mem_clients_normal:33972
mem_aof_buffer:0
mem_allocator:jemalloc-5.1.0
active_defrag_running:0
lazyfree_pending_objects:0

# Persistence
loading:0
rdb_changes_since_last_save:3
rdb_bgsave_in_progress:0
rdb_last_save_time:1606879301
rdb_last_bgsave_status:ok
rdb_last_bgsave_time_sec:1
rdb_current_bgsave_time_sec:-1
rdb_last_cow_size:200704
aof_enabled:0
aof_rewrite_in_progress:0
aof_rewrite_scheduled:0
aof_last_rewrite_time_sec:-1
aof_current_rewrite_time_sec:-1
aof_last_bgrewrite_status:ok
aof_last_write_status:ok
aof_last_cow_size:0
module_fork_in_progress:0
module_fork_last_cow_size:0

# Stats
total_connections_received:9
total_commands_processed:107
instantaneous_ops_per_sec:0
total_net_input_bytes:3636
total_net_output_bytes:227343
instantaneous_input_kbps:0.00
instantaneous_output_kbps:0.00
rejected_connections:0
sync_full:0
sync_partial_ok:0
sync_partial_err:0
expired_keys:0
expired_stale_perc:0.00
expired_time_cap_reached_count:0
expire_cycle_cpu_milliseconds:292
evicted_keys:0
keyspace_hits:4
keyspace_misses:2
pubsub_channels:0
pubsub_patterns:0
latest_fork_usec:164
migrate_cached_sockets:0
slave_expires_tracked_keys:0
active_defrag_hits:0
active_defrag_misses:0
active_defrag_key_hits:0
active_defrag_key_misses:0
tracking_total_keys:0
tracking_total_items:0
tracking_total_prefixes:0
unexpected_error_replies:0

# Replication
role:master
connected_slaves:0
master_replid:f5f98535613d1293befd8f298280c5f9819a8c97
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:0
second_repl_offset:-1
repl_backlog_active:0
repl_backlog_size:1048576
repl_backlog_first_byte_offset:0
repl_backlog_histlen:0

# CPU
used_cpu_sys:15.790574
used_cpu_user:12.802565
used_cpu_sys_children:0.005145
used_cpu_user_children:0.002969

# Modules

# Cluster
cluster_enabled:0

# Keyspace
db0:keys=4,expires=0,avg_ttl=0
db1:keys=1,expires=0,avg_ttl=0
db2:keys=1,expires=0,avg_ttl=0
127.0.0.1:6379>
//////////////////////////////////////////////////////////////////////////////////////

Lab 9: How to restirct maxnoof clients by redis server?

open redis.conf file and edit

################################### CLIENTS ####################################

# Set the max number of connected clients at the same time. By default
# this limit is set to 10000 clients, however if the Redis server is not
# able to configure the process file limit to allow for the specified limit
# the max number of allowed clients is set to the current file limit
# minus 32 (as Redis reserves a few file descriptors for internal uses).
#
# Once the limit is reached Redis will close all the new connections sending
# an error 'max number of clients reached'.
#
# IMPORTANT: When Redis Cluster is used, the max number of connections is also
# shared with the cluster bus: every node in the cluster will use two
# connections, one incoming and another outgoing. It is important to size the
# limit accordingly in case of very large clusters.
#
maxclients 3

Client connections:

$cd src/redis-cli -p 6381
  > set a 10
  ok

$cd src/redis-cli -p 6381
  > set a 10
  ok
$cd src/redis-cli -p 6381
  > set a 10
  ERR MAX NO OF clients reached.

.............................................................................................

Lab 10: What if i want to change configuration while server is running? 

Types of configuration:

1.static configuration
    configuation is applied during server startup.
2.dynamic configuration
    configuration can set after server startup, while running.

static configuration can be loaded
  -from default server config
  -from redis.conf file

how to set /and get configuration dynamically?


How to use change server configuration during server up?

via command 

config set directive value
config get directive
config get * 

config set maxclients 5

config set timeout 1000
///////////////////////////////////////////////////////////////////////////////////////////

How to get Client specific information?

127.0.0.1:6379> client list
id=11 addr=127.0.0.1:42592 fd=8 name= age=6684 idle=4496 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=get user=default
id=12 addr=127.0.0.1:42594 fd=9 name=myclient age=4275 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=26 qbuf-free=32742 obl=0 oll=0 omem=0 events=r cmd=client user=default
127.0.0.1:6379>

How to change client name?

127.0.0.1:6379> client setname myclient
OK
127.0.0.1:6379> client getname
"myclient"
127.0.0.1:6379>
/////////////////////////////////////////////////////////////////////////////////////////////

Monitoring Redis Server:

                     Slow Log : Monitoring Slow Redis Calls.
 
       Monitor commands which are blocking longer time than we specified timeout.


1.The Redis Slow Log is a "system" to log queries that exceeded a specified
execution time.
2.The execution time does not include the I/O operations
like talking with the client, sending the reply and so forth,
but just the time needed to actually execute the command (this is the only
stage of command execution where the thread is blocked and can not serve
other requests in the meantime).

How long a thread can be blocked?

You can configure the slow log with two parameters:
  one tells Redis what is the execution time, in microseconds, to exceed in order for the
command to get logged, and the other parameter is the length of the
slow log. 

When a new command is logged the oldest one is removed from the queue of logged commands.
  

The following time is expressed in microseconds, so 1000000 is equivalent
to one second. Note that a negative number disables the slow log, while
a value of zero forces the logging of every command.

slowlog-log-slower-than 10000

There is no limit to this length. Just be aware that it will consume memory.
You can reclaim memory used by the slow log with SLOWLOG RESET.
slowlog-max-len 128

Lab 11: 

CONFIG SET slowlog-log-slower-than 5000
CONFIG SET slowlog-max-len 50

debug sleep .5

debug commad is used to enable debugging.

sleep command is used to block current for given amount of time.

127.0.0.1:6379> SLOWLOG GET
1) 1) (integer) 1
   2) (integer) 1615980138
   3) (integer) 100146
   4) 1) "debug"
      2) "sleep"
      3) ".10"
   5) "127.0.0.1:43156"
   6) ""
2) 1) (integer) 0
   2) (integer) 1615979917
   3) (integer) 500111
   4) 1) "debug"
      2) "sleep"
      3) ".5"
   5) "127.0.0.1:43156"
   6) ""
/////////////////////////////////////////////////////////////////////////////////////////////

How to monitor memory?

 1) MEMORY <subcommand> [<arg> [value] [opt] ...]. Subcommands are:
 2) DOCTOR
 3)     Return memory problems reports.
 4) MALLOC-STATS    Return internal statistics report from the memory allocator.
 5) PURGE
 6)     Attempt to purge dirty pages for reclamation by the allocator.
 7) STATS
 8)     Return information about the memory usage of the server.
 9) USAGE <key> [SAMPLES <count>]
10)     Return memory in bytes used by <key> and its value. Nested values are
11)     sampled up to <count> times (default: 5).
12) HELP
13)     Prints this help.

127.0.0.1:6379> memory stats
 1) "peak.allocated"
 2) (integer) 933544
 3) "total.allocated"
 4) (integer) 872408
 5) "startup.allocated"
 6) (integer) 809856
 7) "replication.backlog"
 8) (integer) 0
 9) "clients.slaves"
10) (integer) 0
11) "clients.normal"
12) (integer) 20504
13) "aof.buffer"
14) (integer) 0
15) "lua.caches"
16) (integer) 0
17) "db.0"
18) 1) "overhead.hashtable.main"
    2) (integer) 72
    3) "overhead.hashtable.expires"
    4) (integer) 0
19) "overhead.total"
20) (integer) 830432
21) "keys.count"
22) (integer) 1
23) "keys.bytes-per-key"
24) (integer) 62552
25) "dataset.bytes"
26) (integer) 41976
27) "dataset.percentage"
28) "67.105766296386719"
29) "peak.percentage"
30) "93.451194763183594"
31) "allocator.allocated"
32) (integer) 1244440
33) "allocator.active"
34) (integer) 1536000
35) "allocator.resident"
36) (integer) 3772416
37) "allocator-fragmentation.ratio"
38) "1.2342901229858398"
39) "allocator-fragmentation.bytes"
40) (integer) 291560
41) "allocator-rss.ratio"
42) "2.4560000896453857"
43) "allocator-rss.bytes"
44) (integer) 2236416
45) "rss-overhead.ratio"
46) "1.5092290639877319"
47) "rss-overhead.bytes"
48) (integer) 1921024
49) "fragmentation"
50) "6.848081111907959"
51) "fragmentation.bytes"
52) (integer) 4862048
//////////////////////////////////////////////////////////////////////////////////////////////

Latency Check:

Lab 12:
127.0.0.1:6379> CONFIG SET latency-monitor-threshold 100
OK
127.0.0.1:6379> debug sleep 1
OK
(1.00s)
127.0.0.1:6379> latency latest
1) 1) "command"
   2) (integer) 1606872783
   3) (integer) 1000
   4) (integer) 1000
127.0.0.1:6379> debug sleep .25
OK
127.0.0.1:6379> latency latest
1) 1) "command"
   2) (integer) 1606872827
   3) (integer) 250
   4) (integer) 1000
127.0.0.1:6379> latency history command
1) 1) (integer) 1606872783
   2) (integer) 1000
2) 1) (integer) 1606872827
   2) (integer) 250
127.0.0.1:6379> latency doctor
Dave, I have observed latency spikes in this Redis instance. You don't mind talking about it, do you Dave?

1. command: 2 latency spikes (average 625ms, mean deviation 375ms, period 56.00 sec). Worst all time event 1000ms.

I have a few advices for you:

- Check your Slow Log to understand what are the commands you are running which are too slow to execute. Please check http://redis.io/commands/slowlog for more information.
- Deleting, expiring or evicting (because of maxmemory policy) large objects is a blocking operation. If you have very large objects that are often deleted, expired, or evicted, try to fragment those objects into multiple smaller objects.
127.0.0.1:6379>  latency reset command
(integer) 1
127.0.0.1:6379>  debug sleep .1
OK
127.0.0.1:6379>  debug sleep .2
OK
127.0.0.1:6379>  debug sleep .3
OK
127.0.0.1:6379>  debug sleep .5
OK
(0.50s)
127.0.0.1:6379>  debug sleep .4
OK
127.0.0.1:6379> latency graph command
command - high 500 ms, low 100 ms (all time high 500 ms)
--------------------------------------------------------------------------------
   #_
  _||
 _|||
_||||

22219
9523s
ssss
127.0.0.1:6379>
//////////////////////////////////////////////////////////////////////////////////////////////

					Persistence
//////////////////////////////////////////////////////////////////////////////////////////////

What is persistency?

 Redis is in memory data store.
 Once Redis server instance is restarted/shutdown/crashes, all data stored in side redis is   gone. 
 In order to save data permantely, we need to store data in disk.

Why persistency?
 Only for back up and recovery

How Redis takes back up?

 Redis may store datasets into file called "rdb /aof" file.

Redis persistency decisions:
............................

1.rdb - redis database 
2.aof  -append only file
3.no persistency - disabling persistance.
4. rdb + aof


RDB:
1.A .rdb file is a binary that has a point in time representing the data stored in a Redis instance. 
 "Point in time" means a particular moment. persistence not instant based.

 eg 
  if i write "x" data into redis, it may not persent the same inside rdb file.

2.The RDB file format is optimized for fast reads and writes 

3.To achieve the necessary performance, the internal representation of a .rdb file on a disk is very similar to Redis's in-memory representation. 

3.Another interesting aspect of RDB is that it can use LZF compression to make an RDB file very compact. 

4.LZF compression is a fast compression algorithm that has a very small memory requirement during compression 

5.Although it does not have the best compression rates compared to other compression algorithms, it works efficiently with Redis. Also, a single RDB file is sufficient to restore a Redis instance completely. 


6.When we can take back up?
 RDB is great for backups and disaster recovery because it allows you to save an RDB file every hour, day, week, or month, depending on your needs. This approach allows you to easily use RDB files to restore any dataset at any given time. 

7.How to start taking back up?

 -via commands
 -via configuration.

Commands:
1.Save
2.bgsave

The command SAVE creates an RDB immediately, but it should be avoided because it blocks the Redis server during snapshot(Exact copy) creation. 

The command BGSAVE (background save) should be used instead; it has the same effect as SAVE, but it runs in a child process so as not to block Redis. 

8.In order to avoid performance degradation during a background save, the redis-server process creates a child process (fork) to perform all the persistence operations. 

9.So, the main process will never perform any disk I/O operations. 
During this process, if the main redis-server is receiving writes, the child process will need to copy the memory pages that were changed, and this may increase the total used memory significantly (it uses copy-on-write). 

Snapshot Rules:
...............

The default Redis configuration file has enabled three snapshot rules to cause the data to persist on the disk through the directive save, which performs background saves This technique is called snapshotting . 
“redis.conf” file having the below configuration
save 900 1 
save 300 10 
save 60 10000 

Redis creates snapshots based on two conditions:
 if in X seconds, Y amount of write operations have happened in your Redis instance, it will create a .rdb file. 
The RDB filename is based on the directive dbfilename (this defaults to dump.rdb) .
save number_of_seconds number_of_changes 
With this in mind, we can infer what those three lines will do: 
Save a .rdb file on disk every 900 seconds (15 minutes) if at least one write operation happens. 
Save a .rdb file on disk every 300 seconds (5 minutes) if at least 10 write operations happen. 
Save a .rdb file on disk every 60 seconds (1 minute) if at least 10,000 write operations happen. 


Lab 13:

Change redis.conf file and check 
Save and bgsave commands and check the status

Not recommended to use save directives less than 30 seconds 


How to disable snapshot

Snapshotting can be disabled, which means that nothing will be saved on the disk. 
This is done by deleting or commenting all save directives in the redis.conf file and then restarting the Redis server.
 It can also be disabled via a command-line option or the command CONFIG SET 

Snapshot additional directives:
stop-writes-on-bgsave-error: The possible values for this are yes or no. This option makes Redis stop accepting writes if the last background save has failed. Redis starts accepting writes again after a background save succeeds. The default value is yes 

rdbcompression: The possible values for this are yes or no. When this option is set to yes, Redis uses LZF compression for the .rdb files. The default value is yes 

rdbchecksum: The possible values for this are yes or no. When it is set to yes, Redis saves a checksum at the end of the .rdb file and performs a checksum before loading the .rdb file. Redis does not start if the RDB checksum does not match with the one in the file. The default value is yes 

dbfilename: This option sets the .rdb filename. The default value is dump.rdb 
save: This option configures the snapshot frequency, based on the number of seconds and changes. It can be specified multiple times. The default values are save 3600 1, save 300 100, and save 60 10000 

dir: This specifies the directory location of the AOF and RDB files 


AOF (Append-only File):

1.The AOF persistence logs every write operation received by the server, that will be played again at server startup, reconstructing the original dataset. 
   set a 10 ------------------file.aof ----set a 10
 Rdb stores data in binary format.

2.Commands are logged using the same format as the Redis protocol itself, in an append-only fashion.
 Redis is able to rewrite the log in the background when it gets too big.
//////////////////////////////////////////////////////////////////////////////////////////////

As of now we have discussed single server instance only. Redis has been designed to support 
"Scalability and High Availability"
.............................................................................................
                                   Scalability : Replication
.............................................................................................

What is replication?
   Replication means that while you write to a Redis instance (usually referred to as the
master), it will ensure that one or more instances (usually referred to as the slaves)
become exact copies of the master.

One Leader(Master) many followers(slaves/replicas)

Replication is another form of persistency. Persistency will avoid data loss.

Types of Persistency:
1.Disk based persistency -  rdb /aof
2.Disk less persistency -  in memoery persistency.

Roles of redis instance

1.master
   receives write operation, replicates to another instances called replica
   master can do both read and write
   a single master must have 2 replica min
   replication is async and non blocking process

2.replica
   it is redis instance , replicates data of master
   it is read only.
   one replica can become master to another replica

Communication pattern between master and replica:

 master and replica connected , the master  keeps the replicated updated
 by sending a stream of commands to replica(ping).
  it replicates  effects on the dataset happening in the master side due to
 client writes, keys expired or evicted, any other action changing the master dataset.

Synchronization:
  Connecting master and replica and starts sending data(stream of commands).

 when the link between master and the replica breaks, due to network issues, or timeout sensed in the master or the replica.

Use case:

  client sends 3 commands to the master------ master has replicated only 2 commands whil   replicating 1 command network is gone.what will happen to that 1 commands.

Types of Replication:
....................

1.Full Sync
    1.tries to transfer full data  to replica
    2.dump not saved on master in diskless mode
When:
    bootrap new a new replica
    Existing replica too far behind to do partial sync.

2.Partial sync
    every write operation in master
    it wont replicate old data.

client sends 3 commands to the master------ master has replicated only 2 commands whil   replicating 1 command network is gone.what will happen to that 1 commands.

 Will it go full sync or partil sync?
   By default it will do partil resync, if paritial is not available,if full sync..

While full resync, master internally takes snapshot, then after that it will send commands.
////////////////////////////////////////////////////////////////////////////////////////////

Big Picture on Data storage inside redis-master instance/slave Instance:(Memory layout)
.......................................................................................

There are 3 memory layout inside redis instance:

1.Backlog Circular buffer
2.Key-Value Store
3.Replica Client Output Buffer /OUtput buffer

In Enterprise, you can have many masters, each master can have more replication.

Each master identified by "replication id" : it long random pseudo string.


How to write replication ?

1.via redis config
2.via command line
3.via config command

Lab 13:
 How to setup 1 master 2 replicas.

Master:

$ redis-server --port 5555
  On the second terminal, start the first slave on port 6666:


Replicas:
Steps:
The following example starts three Redis instances: one master and two replicas.

On the first terminal, start the master redis-server on port 5555:

$ redis-server --port 5555
  On the second terminal, start the first slave on port 6666:

$ redis-server --port 6666 --slaveof 127.0.0.1 5555

On the third terminal, start the second slave on port 7777:
$ redis-server --port 7777 --slaveof 127.0.0.1 5555
At this point, there is a master with two replicas running.

On the fourth terminal, check whether the replication is working:
$ redis-cli -p 5555 SET testkey testvalue
OK
$ redis-cli -p 6666 GET testkey
"testvalue"
$ redis-cli -p 7777 GET testkey
"testvalue"
//////////////////////////////////////////////////////////////////////////////////////////////
                                  High Availability
/////////////////////////////////////////////////////////////////////////////////////////////

Partition:
..........
Divide /break up

Partition in genernal term used to describe the act of breaking up data and distributing  it across different hosts.

Redis Persistency Models:

Single Instance:
  
  The whole data set is stored inside in one node,eg i have 5 million keys, all stored in one node.
 For backup and recover we move in memory to disk - rdb/aof.

Which is not scableable? 

Multi instance: Replication
   Instead keeping the whole data inside one machine/node we take snapshot - replicas
 eg i have 5 million keys , all keys are distribtued into all nodes.

Still it is not scalable, because we dump all keys into single server(master/slave).

How to distribute 5 million keys across multiple nodes(master)
 
  Partition
Breaking One Master Database data and share across multiple masters


What Partition?

 Partitioning is performed in a cluster of hosts when better performance, maintainability, or availability is desired.

When Redis was initially designed, it had no intention to be a distributed data store; thus, it cannot natively distribute its data among different instances. It was designed to work well on a single server. 

Types of Partition?

1.Horizontal partitioning 
2.Vertical partitioning

Horizontal partitioning:
........................

Horizontal partitioning  means distributing "keys" across different redis instances.
   -Key distribtion

Vertical partitioning:
........................

Vertical partitioning distributing "key values" across differnt redis instances
  -Values

For example, if you have two Redis List/set/string/number stored in Redis, horizontal partitioning would distribute each Set entirely to a different Redis instance, while vertical partitioning would distribute the Set's values to different instances


Horizontal partitioning (also known as sharding) is the most popular approach adopted with Redis
/////////////////////////////////////////////////////////////////////////////////////////////
Where and How  to implement Partition?

Client side
  The application programs can decide how to distribute keys to redis instances

Server Side
   Redis servers can decide how to distribute keys across multiple nodes
Proxy Side
   Even proxy, can decide where to distribute keys.


Client side Distribtution:
 in order to distributes there are multiple algorthims.

1.Range Partition

Range partitioning is very simple; data is distributed based on a range of keys. Assuming that the keys you want to partition are based on incremental IDs, you can create numerical ranges to partition the data. For example, assuming that you have a group of users identified by IDs (such as user:1, user:2, and so on up to user:5000) you can split these IDs into ranges of thousands. Then you can send keys that go from 1 to 1000 to a given instance, 1001 to 2000 to a different instance, 2001 to 3000 to another instance, and so on.

Another way to distributed based on "Alphabets" a to g one server h-o another server......

2.Hash partitioning

Hash partitioning is very simple to implement. It consists of finding the instance to send the commands by applying a hash function to the Redis key, dividing this hash value by the number of Redis instances available, and using the remainder of that division as the instance index. 
var index = hashFunction(redisKey) % redisHosts.length; 
var host = redisHosts[index]; 

It is common algorthim is used called MD5 and SHA1 as hashfunction

2.1.Presharding
     If nodes are added or removed dynamically over time with hash partitioning is "to preshard". This is nothing but pre partition the data to high extent so that the host
list size never changes.

2.2.consistent hashing
   Consistent hashing is a kind of hashing that remaps only a portion of the data to different servers when the list of redis service changed

3.Tagging:
 Tagging is a technique of ensuring keys are distribtued across multiple servers, based on
keynames with prefix or suffix.

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&...........................&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

Hashing is most popular one used in servers side as well with consistent hashing
.........................................................................................

Automatic Sharding: 

1.Via proxy layer ; twemproxy.

Steps:

1.download nutcracker 
2.build it
3.create nutcracker  config file - containing all redis informations
   -hash alogorthim,master nodes mapping
4.start netcuracker
  /src/nutcracker  -c twemproxy.yml

5.write cilent program-java/js/rube, try to connect to proxy.

2.Via Redis Node Monitoring services: Redis Sentinel /  Redis Cluster
    
 
High Availability and Scalability:
..................................
1.In 2011, Salvatore Sanfilippo started working on a project that would solve these problems, but Redis was still underdeveloped.
 
2.He decided to stop his work because of requests from the community to support other features, such as persistence, better data types, introspection, and replication. 
In 2011, he did not have a lot of knowledge about distributed systems, and Redis Cluster was a complex project to create. It was a great idea, but it required more experience than he had at that time. Solving all of these problems was a difficult task, so he decided to tackle only automatic failover and created a project called Redis Sentinel 

Redis Cluster And Redis Sentinel:
	
Redis Sentinel became stable in Redis 2.8 in late 2013, and Redis Cluster became stable in Redis 3.0 in early 2015. 
Sentinel's goal is to provide reliable automatic failover in a master/slave topology without sharding data. Cluster's goal is to distribute data across different Redis instances and perform automatic failover if any problem happens to any master instance 


Redis Cluster:

Redis Cluster was designed to automatically shard data across different Redis instances, providing some degree of availability during network partitions.

Redis Cluster only requires a single process to run.
However, there are two ports that Redis uses. The first is used to serve clients (low port), and the second serves as a bus for node-to-node communication (high port). The high port is used to exchange messages such as failure detection, failover, resharding, and so on.

The Redis Cluster bus uses a binary protocol to exchange messages between nodes.
The low port is specified in the configuration, and Redis assigns the high port by adding 10,000 to the low port. For example, if a Redis server starts listening to port 6379 (low port) in cluster mode, it will internally assign port 16379 (high port) for node-to-node communication.
The Redis Cluster topology is a full mesh network. All nodes are interconnected through Transmission Control Protocol (TCP) connections
Redis Cluster requires at least three masters, as shown in the following figure, to be considered healthy. All data is sharded across the masters and replicated to the slaves


Hash slots:

The partitioning method used to shard data by Redis Cluster is similar to the hash partitioning but the method is always applied on top of a fixed value. 
In Redis Cluster, that fixed value is 16,384. Redis calls this method hash slot. 
Each master in a cluster owns a portion of the 16,384 slots.
The hash slot is found by using the CRC-16 hash function to convert the key into an integer, and then calculating modulo 16,384 of that integer. The following pseudocode illustrates how a hash slot is calculated for a given key:
HASH_SLOT = CRC16(key) mod 16384


Lab : 

Setup cluster:

1.From command line

2.via cluster automation script

3.via Redis enterprise cluster configuration dashboard.



Basic cluster config parameters:

cluster-enabled yes
cluster-config-file cluster.conf
cluster-node-timeout 2000
cluster-slave-validity-factor 10
cluster-migration-barrier 1
cluster-require-full-coverage yes


Cluster Configuration Basic steps

1.start redis server in cluster mode

2.Sharding - Hash Slot

3.Node meetup ; cluster meet


Master-Slave Attachment

cluster-enabled yes
cluster-config-file cluster.conf
cluster-node-timeout 2000
cluster-slave-validity-factor 10
cluster-migration-barrier 1
cluster-require-full-coverage yes

src/redis-server --port 5000 --cluster-enabled yes --cluster-config-file \ 
nodes-5000.conf --cluster-node-timeout 2000 --cluster-slave-validity-factor \
10 --cluster-migration-barrier 1 --cluster-require-full-coverage \
yes --dbfilename dump-5000.rdb --daemonize yes \

src/redis-server --port 5001 --cluster-enabled yes --cluster-config-file \
nodes-5001.conf --cluster-node-timeout 2000 --cluster-slave-validity-factor \
10 --cluster-migration-barrier 1 --cluster-require-full-coverage \
yes --dbfilename dump-5001.rdb --daemonize yes


src/redis-server --port 5002 --cluster-enabled yes --cluster-config-file \
nodes-5002.conf --cluster-node-timeout 2000 --cluster-slave-validity-factor \
10 --cluster-migration-barrier 1 --cluster-require-full-coverage \
yes --dbfilename dump-5002.rdb --daemonize yes


cluster-node-timeout (this value is in milliseconds). 
.....................................................

 If a node is not reachable for the specified amount of time by the
majority of master nodes, it will be considered as failing.

If that node is a master, a failover to one of its slaves will occur. If it is a slave, it will stop accepting queries.

cluster-slave-validity-factor:

-Sometimes, network failures happen, and when they happen, it is always a good
idea to minimize problems.

-If network issues are happening and nodes cannot communicate well, it is possible that the majority of nodes think that a given master is down and so a failover procedure should start

-If the network only had a hiccup, the failover procedure might have been unnecessary. 
There is a configuration directive that helps minimize these kinds of problems. 

-The directive is cluster-slave-validity-factor, and it expects a factor. By default, the factor is 10.

If there is a network issue and a master node cannot communicate well with other nodes for a certain amount of time (cluster-node-timeout multiplied by cluster-slave-validity-factor),
no slaves will be promoted to replace that master.

When the connection issues go away and the master node is able to communicate well with others again, if it becomes unreachable a failover will happen.

When the factor is set to zero, no failovers will be prevented. If any network connectivity issues occur and the factor is zero, a slave will always perform the failover.

cluster-migration-barrier:
..........................

It is possible to specify the minimum number of slaves that must be connected
to a master through the directive cluster-migration-barrier, which has a default
value of 1.

This directive is useful if you need to ensure a minimum number of
slaves per master. Otherwise, masters without slaves will borrow spare slaves
from other masters.

Use case:
Take the following example: master A has A1 and A2 as slaves, master B has B1 as a
slave, master C has C1 as a slave, and the directive cluster-migration-barrier is set to
2. If master C fails and C1 gets promoted to master, master A will keep all of its slaves
(because the minimum is 2), and master C1 will have zero slaves.

If you never want to have masters borrowing slaves from other masters, set this configuration to a high number

In Redis Cluster, all data is sharded among master nodes.

If any master node fails and there is no slave to fail over to, a portion of the data will be lost. When this happens,

you have two options:
• Make the entire cluster unavailable
• Make the cluster available, but such that all keys that would be routed to that
master node will result in an error.

cluster-require-full-coverage

The directive that controls this behavior is cluster-require-full-coverage. By default, it
is yes. Full coverage means that all 16,384 hash slots are assigned to reachable masters
If this directive is set to yes, all hash slots must be reachable. Otherwise, the entire
cluster will be unavailable.

If it is set to no, the cluster will still be available, but queries
that route to hash slots assigned to any unreachable masters will result in errors
//////////////////////////////////////////////////////////////////////////////////////

Setup from scratch


$ redis-server --port 5000 --cluster-enabled yes --cluster-config-file
nodes-5000.conf --cluster-node-timeout 2000 --cluster-slave-validityfactor
10 --cluster-migration-barrier 1 --cluster-require-full-coverage
yes --dbfilename dump-5000.rdb --daemonize yes

$ redis-server --port 5001 --cluster-enabled yes --cluster-config-file
nodes-5001.conf --cluster-node-timeout 2000 --cluster-slave-validityfactor
10 --cluster-migration-barrier 1 --cluster-require-full-coverage
yes --dbfilename dump-5001.rdb --daemonize yes

$ src/redis-server --port 5002 --cluster-enabled yes --cluster-config-file
nodes-5002.conf --cluster-node-timeout 2000 --cluster-slave-validityfactor
10 --cluster-migration-barrier 1 --cluster-require-full-coverage
yes --dbfilename dump-5002.rdb --daemonize yes

The cluster is not ready to run yet. We can check the cluster's health with the
CLUSTER INFO command:

$ redis-cli -c -p 5000
127.0.0.1:5000> CLUSTER INFO

cluster_state:fail
cluster_slots_assigned:0
cluster_slots_ok:0
cluster_slots_pfail:0
cluster_slots_fail:0
cluster_known_nodes:1
cluster_size:0
cluster_current_epoch:0
cluster_my_epoch:0
cluster_stats_messages_sent:0
cluster_stats_messages_received:0

127.0.0.1:5000> SET foo bar
(error) CLUSTERDOWN The cluster is down

The output of CLUSTER INFO tells us that the cluster only knows about one node
(the connected node), no slots are assigned to any of the nodes, and the cluster state
is fail.
When the cluster is in the fail state, it cannot process any queries, as we could see
when we tried to execute the SET command.

Next, the 16,384 hash slots are distributed evenly across the three instances.

The configuration cluster-require-full-coverage is set to yes, which means that the

cluster can process queries only if all hash slots are assigned to running instances:

$ redis-cli -c -p 5000 CLUSTER ADDSLOTS {0..5460}
$ redis-cli -c -p 5001 CLUSTER ADDSLOTS {5461..10922}
$ redis-cli -c -p 5002 CLUSTER ADDSLOTS {10923..16383}

The preceding shell lines use a range trick to expand the numbers. They take the
starting number and the ending number and expand them into separate numbers.
It is the same as passing 0, 1, 2, 3, 4, 5, and so on up to 5460 to the first line.

The CLUSTER ADDSLOTS command informs the node what slots it should own.
If a hash slot is already assigned, this command fails. It is possible to assign slots one
by one; it does not need to be a sequence of numbers.

At this point, the hash slots are distributed evenly across the nodes, but the cluster is
not ready yet. The cluster nodes still do not know about each other.

configuration epoch:

In Redis Cluster, there is a concept called configuration epoch, which is a number that
represents the cluster state at a particular point in time.

This number is used when new events occur and the nodes need to agree on what is
going to happen next (such as failover or resharding of hash slots).
When a cluster is initially created, the configuration epoch is set to 0 for each master.
We can change this to help Redis start the cluster in a safe way. This is the only
time when the configuration epoch should be changed manually. Redis Cluster
automatically changes the configuration after it is up and running:

$ redis-cli -c -p 5000 CLUSTER SET-CONFIG-EPOCH 1
$ redis-cli -c -p 5001 CLUSTER SET-CONFIG-EPOCH 2
$ redis-cli -c -p 5002 CLUSTER SET-CONFIG-EPOCH 3

This example executes the command CLUSTER SET-CONFIG-EPOCH to manually
set an incremental epoch to each node, which is good practice when starting a new
cluster. In this example, there is no conflicting information. However, if there was
conflicting information (for example, if two different nodes claimed the same hash
slots), the largest epoch configuration would have priority.

Next, we are going to make all the nodes aware of each other. We will do this using


the command CLUSTER MEET:
$ redis-cli -c -p 5000 CLUSTER MEET 127.0.0.1 5001
$ redis-cli -c -p 5000 CLUSTER MEET 127.0.0.1 5002

It is not necessary to execute CLUSTER MEET on each node to notify it about the
existence of all the other nodes. When the first node meets the second, it means that
the second node also knows about the first, and they can exchange information about
other nodes that they know. When the first node meets the third node, all three
nodes will know about each other eventually, through the gossip protocol that Redis
Cluster implements.

Run the command CLUSTER INFO to see that the cluster is up and running:
$ redis-cli -c -p 5000
127.0.0.1:5000> CLUSTER INFO
cluster_state:ok
cluster_slots_assigned:16384
cluster_slots_ok:16384
cluster_slots_pfail:0
cluster_slots_fail:0
cluster_known_nodes:3
cluster_size:3
cluster_current_epoch:3
cluster_my_epoch:1
cluster_stats_messages_sent:164
cluster_stats_messages_received:144


Adding slaves/replicas:
.......................

There are three master nodes but no slaves. Thus, no data is replicated anywhere.
This is not very safe. Data can be lost, and if any master has issues, the entire cluster
will be unavailable (cluster-require-full-coverage is set to yes).

A new slave/replica can be added to the cluster by:

• Creating a new Redis instance in cluster mode

• Introducing it to the current cluster using the command CLUSTER MEET

• Getting the node ID of the master that will be replicated using the command
CLUSTER NODES
• Executing the command CLUSTER REPLICATE to replicate a given node

Create a new Redis instance in cluster mode:

$ redis-server --port 5003 --cluster-enabled yes --cluster-config-file
nodes-5003.conf --cluster-node-timeout 2000 --cluster-slave-validityfactor
10 --cluster-migration-barrier 1 --cluster-require-full-coverage
yes --dbfilename dump-5003.rdb --daemonize yes

Introduce it to the current cluster using the command CLUSTER MEET:
$ redis-cli -c -p 5003 CLUSTER MEET 127.0.0.1 5000

Get the node ID of the master that is going to be replicated by using the command
CLUSTER NODES:

$ redis-cli -c -p 5003 CLUSTER NODES

b5354de29d7ec02e64580658d3f59422cfeda916 127.0.0.1:5002 master - 0
1432276450590 3 connected 10923-16383
08cbbb4c05ec977af9c4925834a71971bbea3477 127.0.0.1:5003 myself,master - 0
0 0 connected
68af8b5f533abae1888312a2fecd7cbe4ac77e0a 127.0.0.1:5001 master - 0
1432276449782 2 connected 5461-10922
f5940c6bcd6f06abb07f7d480b16630b6a597424 127.0.0.1:5000 master - 0
1432276449782 1 connected 0-5460

The command CLUSTER NODES outputs a list with all the nodes that belong to
the cluster, along with their properties. Every line follows this format: <node-id>
<ip:port> <flags> <master> <ping-sent> <pong-recv> <config-epoch> <link-state> <slots>.

Let's replicate the instance running on port 5000. The output shows that the node ID
for this instance is f5940c6bcd6f06abb07f7d480b16630b6a597424.
Since the node ID is generated randomly using /dev/urandom, all CLUSTER NODES
outputs in our examples are merely for demonstration.

...........................................................................................

Create a replica:

Execute the command CLUSTER REPLICATE to replicate a given node:

$ redis-cli -c -p 5003 CLUSTER REPLICATE
f5940c6bcd6f06abb07f7d480b16630b6a597424

The replica is ready and CLUSTER NODES can confirm this:

$ redis-cli -c -p 5003 CLUSTER NODES

b5354de29d7ec02e64580658d3f59422cfeda916 127.0.0.1:5002 master - 0
1432276452608 3 connected 10923-16383
08cbbb4c05ec977af9c4925834a71971bbea3477 127.0.0.1:5003 myself,slave
f5940c6bcd6f06abb07f7d480b16630b6a597424 0 0 0 connected
68af8b5f533abae1888312a2fecd7cbe4ac77e0a 127.0.0.1:5001 master - 0
1432276452608 2 connected 5461-10922
f5940c6bcd6f06abb07f7d480b16630b6a597424 127.0.0.1:5000 master - 0
1432276451800 1 connected 0-5460

The first output line is the slave information. It said myself,master previously, and
after CLUSTER REPLICATE, it became myself,slave.

src/redis-cli -c -h localhost -p 30001
////////////////////////////////////////////////////////////////////////////////////////////

Setup Cluster via config files:

Create servers- create that many folders

 server-5000 server-5001 server-5002 server-5003...

  
each folder can have redis distribution 
where you can have redis.conf

port 5000
cluster-enabled yes
cluster-config-file 500-nodes.conf
cluster-node-timeout 5000
appendonly yes

src/redis-server redis.conf
/////////////////////////////////////////////////////////////////////////////////////////////

via server start:

3 master 3 slaves = 6 nodes

src/redis-server --port 5000 --cluster-enabled yes --cluster-config-file \ 
nodes-5000.conf --cluster-node-timeout 2000 --cluster-slave-validity-factor \
10 --cluster-migration-barrier 1 --cluster-require-full-coverage \
yes --dbfilename dump-5000.rdb --daemonize yes \

src/redis-server --port 5001 --cluster-enabled yes --cluster-config-file \
nodes-5001.conf --cluster-node-timeout 2000 --cluster-slave-validity-factor \
10 --cluster-migration-barrier 1 --cluster-require-full-coverage \
yes --dbfilename dump-5001.rdb --daemonize yes


src/redis-server --port 5002 --cluster-enabled yes --cluster-config-file \
nodes-5002.conf --cluster-node-timeout 2000 --cluster-slave-validity-factor \
10 --cluster-migration-barrier 1 --cluster-require-full-coverage \
yes --dbfilename dump-5002.rdb --daemonize yes

...create other 3 nodes with different portno

Incase it is manual setp

1.HASH slot allocation
2.cluster meet step
3.replication

Redis 5 on wards this has been simplified via redis cli


src/redis-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001 \
127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 \
--cluster-replicas 1

This command will setup hash slot allocation, cluster meet config,replication config.
////////////////////////////////////////////////////////////////////////////////////////////

Redis provides an utility:
-ruby utility
-sh utility.

Create-Cluster utiltity command to setup cluster.
/////////////////////////////////////////////////////////////////////////////////////////////
                                  Security
////////////////////////////////////////////////////////////////////////////////////////////

Redis General Security Architecture:
...................................
1.Redis has been designed to be accessed by trusted clients inside trusted envs.
  - It is not good idea to expose the redis instance directly to the internet or to an env
    Where untrusted clients can directly access the Redis TCP PORT or Unix socket.
 
In general web applications will talk to redis for storing data, there is high possiblity
via application hacker may enter into redis.

How to stop that?
 Redis recommands to implement ACL- ACCESS CONTROL List , through which you can validate
user, what operation he can perform against redis instance.

Network Security:
................

bind:

# ~~~ WARNING ~~~ If the computer running Redis is directly exposed to the
# internet, binding to all the interfaces is dangerous and will expose the
# instance to everybody on the internet. So by default we uncomment the
# following bind directive, that will force Redis to listen only on the
# IPv4 loopback interface address (this means Redis will only be able to
# accept client connections from the same host that it is running on).

# bind 192.168.1.100 10.0.0.1
# bind 127.0.0.1 ::1

Protected Mode:
 if redis instance is exposed outside , accessed from external network.


 # When protected mode is on and if:
#
# 1) The server is not binding explicitly to a set of addresses using the
#    "bind" directive.
# 2) No password is configured.
#
# The server only accepts connections from clients connecting from the
# IPv4 and IPv6 loopback addresses 127.0.0.1 and ::1, and from Unix domain
# sockets.
#
# By default protected mode is enabled. You should disable it only if
# you are sure you want clients from other hosts to connect to Redis
# even if no authentication is configured, nor a specific set of interfaces
# are explicitly listed using the "bind" directive.
protected-mode yes
//////////////////////////////////////////////////////////////////////////////////////

How to disable danagerous commands
like flush db, flushall, config

redis.conf

rename-command commandName newCommand

rename-command  flushdb   b888adfdsafdsafkk8888

127.0.0.1:6379> flushdb
(error) ERR unknown command `flushdb`, with args beginning with:
127.0.0.1:6379>


///////////////////////////////////////////////////////////////////////////////////////////

User Passwords: Authentication: ACL Framework:
..............................................

What is redis acl? 
 Access Control List, is the feature that allows certain connections to be limited in the
terms of commands that can be executed and keys that can be accessed.

The redis is configured with "default" user without any password.

In old redis versions the passed is configured using a directive called "requirepass".

Lab:

open redis.conf file

requirepass foo

try to connect redis cli with out pass

src/redis-cli
ubuntu@ip-172-31-16-143:~/myredislab/redis-6.2.1$ src/redis-cli
127.0.0.1:6379> ping
(error) NOAUTH Authentication required.

how to connect with password?
ubuntu@ip-172-31-16-143:~/myredislab/redis-6.2.1$ src/redis-cli -a foo
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
127.0.0.1:6379> ping
PONG
///////////////////////////////////////////////////////////////////////////////////////// 

Auth Command:
..............

AUTH username password

//////////////////////////////////////////////////////////////////////////////////////

ACL Commands

- acl users
   The command shows a list of all the usernames of the currently configured users in the Redis ACL system.

How to add new user with rules?

-ACL SETUSER username [rule [rule ...]]

ACL List
127.0.0.1:6379> acl list
1) "user default on nopass ~* +@all"
127.0.0.1:6379>

Add simple user:
127.0.0.1:6379> acl setuser alice
OK
127.0.0.1:6379> acl list
1) "user alice off -@all"
2) "user default on nopass ~* +@all"
127.0.0.1:6379>

The just created user "alice" is:

In off status, that is, it's disabled. AUTH will not work.
The user also has no passwords set.
Cannot access any command. Note that the user is created by default without the ability to access any command, so the -@all in the output above could be omitted, however ACL LIST attempts to be explicit rather than implicit.
There are no key patterns that the user can access.
The user can access all Pub/Sub channels.

127.0.0.1:6379> ACL SETUSER alice on >mypass ~cached:* +get
OK
1
> AUTH alice p1pp0
OK
> GET foo
(error) NOPERM this user has no permissions to access one of the keys used as arguments
> GET cached:1234
(nil)
> SET cached:1234 zap
(error) NOPERM this user has no permissions to run the 'set' command or its subcommand
///////////////////////////////

127.0.0.1:6379> ACL WHOAMI
"default"
1

for rules : refere redis.conf file.
/////////////////////////////////////////////////////////////////////////////////////////////
                                 Upgrading a Server
/////////////////////////////////////////////////////////////////////////////////////////////

UpGrading:

At some point in the life of your system you might need to upgrade Redis. Unfortunately,
Redis can’t do online binary upgrades, and doing a server restart means that
your application won’t be able to talk to Redis for a (possibly long) period of time. But
that doesn’t mean that there aren’t other ways to achieve it without incurring downtime.
You might also want to move your current Redis database to another system for
maintenance purposes, a hardware upgrade, etc.

Solution:

Our solution will involve starting a new Redis server in slave mode, switching over the
clients to the slave and promoting the new server to the master role. To make the
example easier to understand, let’s assume we have a Redis server listening on port
6379.

Steps:

1. Install the new Redis version without restarting your existing server.

2. Create a new redis.conf, specifying that Redis runs on port 6380 (assuming you’re
on the same system—if you’re not, you can still use 6379 or any other available
port) and a different DB directory (you don’t want to have 2 Redis servers reading
or writing the same files).

3. Start the new server.

4. Connect to the new server and issue the command:
 
  SLAVEOF localhost 6379

This will trigger a BGSAVE on the master server, and upon completion the new (slave)
server will start replicating. You can check the current status using the INFO command
on the slave. When you see master_link_status:up, the replication is active.

5. Since your new Redis server is now up-to-date, you can start moving over your
clients to this new server. You can verify the number of clients connected to a server
with the INFO command; check the connected_clients variable.

6. When all your clients are connected to the slave server, you still have two tasks to
complete: disable the replication and shut down the master server



1. Connect to the slave server and issue:

SLAVEOF NO ONE

This will stop replication and effectively promote your slave into a master. This is
important in Redis 2.2. as master servers are responsible for sending expirations
to their slaves.

2. Now connect to your old master server and issue:

SHUTDOWN
The old master server will perform a SAVE and shutdown.

3. Your new Redis system is up and running, but make sure that all your configuration
files, init scripts, backups, etc. are pointing to the right location and starting the
correct server. It’s easy to forget those routine operations, but you should at the
very least certify that nothing wrong will happen in case of a server restart.
///////////////////////////////////////////////////////////////////////////////////////////

Redis Basic setup guidelines:
............................











































  




